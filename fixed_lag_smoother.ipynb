{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fixed_lag_smoother.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peterchang0414/hmm-jax/blob/main/fixed_lag_smoother.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fixed Lag Smoother - Unit Tests\n",
        "\n",
        "This notebook demonstrates the following: \n",
        "\n",
        "1. the correctness of a JAX-ified version of fixed lag smoother by comparison of its full-lag smoothed posterior with the results of JSL's implementation of `hmm_forwards_backwards_jax`;\n",
        "\n",
        "2. the improved \"online\" performance of a version that uses a vectorized approach to compute the $\\beta$ values across its sliding window against the one that iteratively smooths backwards inside the window, as implemented in Kevin Murphy's HMM Toolbox for Matlab. \n",
        "\n",
        "The JAX State-Space Models Library (JSL) is available at:\n",
        "https://github.com/probml/JSL\n",
        "\n",
        "Kevin Murphy's Hidden Markov Model (HMM) Toolbox for Matlab is available at:\n",
        "https://www.cs.ubc.ca/~murphyk/Software/HMM/hmm.html"
      ],
      "metadata": {
        "id": "YNVwtTv8P0bZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Imports"
      ],
      "metadata": {
        "id": "Fob7r0qaR1Nk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q flax"
      ],
      "metadata": {
        "id": "vR05NbgRYED1"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "W6I7FjHfR5IC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference and learning code for Hidden Markov Models using discrete observations.\n",
        "# Has Jax version of each function. For the Numpy version, please see hmm_numpy_lib.py\n",
        "# The Jax version of inference (not learning)\n",
        "# has been upstreamed to https://github.com/deepmind/distrax/blob/master/distrax/_src/utils/hmm.py.\n",
        "# This version is kept for historical purposes.\n",
        "# Author: Gerardo Duran-Martin (@gerdm), Aleyna Kara (@karalleyna), Kevin Murphy (@murphyk)\n",
        "\n",
        "from jax import lax\n",
        "from jax.scipy.special import logit\n",
        "from functools import partial\n",
        "\n",
        "import jax.numpy as jnp\n",
        "from scipy.special import softmax\n",
        "from jax import vmap\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import jax\n",
        "import itertools\n",
        "from jax import jit\n",
        "from jax.nn import softmax\n",
        "from jax.random import PRNGKey, split, normal\n",
        "from jax.random import split, randint, PRNGKey, normal, permutation\n",
        "\n",
        "import flax\n",
        "\n",
        "'''\n",
        "Hidden Markov Model class used in jax implementations of inference algorithms.\n",
        "The functions of optimizers expect that the type of its parameters \n",
        "is pytree. So, they cannot work on a vanilla dataclass. To see more:\n",
        "                https://github.com/google/jax/issues/2371\n",
        "Since the flax.dataclass is registered pytree beforehand, it facilitates to use\n",
        "jit, vmap and optimizers on the hidden markov model.\n",
        "'''\n",
        "\n",
        "\n",
        "@flax.struct.dataclass\n",
        "class HMMJax:\n",
        "    trans_mat: jnp.array  # A : (n_states, n_states)\n",
        "    obs_mat: jnp.array  # B : (n_states, n_obs)\n",
        "    init_dist: jnp.array  # pi : (n_states)\n",
        "\n",
        "\n",
        "def normalize(u, axis=0, eps=1e-15):\n",
        "    '''\n",
        "    Normalizes the values within the axis in a way that they sum up to 1.\n",
        "    Parameters\n",
        "    ----------\n",
        "    u : array\n",
        "    axis : int\n",
        "    eps : float\n",
        "        Threshold for the alpha values\n",
        "    Returns\n",
        "    -------\n",
        "    * array\n",
        "        Normalized version of the given matrix\n",
        "    * array(seq_len, n_hidden) :\n",
        "        The values of the normalizer\n",
        "    '''\n",
        "    u = jnp.where(u == 0, 0, jnp.where(u < eps, eps, u))\n",
        "    c = u.sum(axis=axis, keepdims=True)\n",
        "    c = jnp.where(c == 0, 1, c)\n",
        "    return u / c, c\n",
        "\n",
        "\n",
        "##############################\n",
        "# Inference\n",
        "\n",
        "def hmm_forwards_jax(params, obs_seq, length=None):\n",
        "    '''\n",
        "    Calculates a belief state\n",
        "    Parameters\n",
        "    ----------\n",
        "    params : HMMJax\n",
        "        Hidden Markov Model\n",
        "    obs_seq: array(seq_len)\n",
        "        History of observable events\n",
        "    Returns\n",
        "    -------\n",
        "    * float\n",
        "        The loglikelihood giving log(p(x|model))\n",
        "    * array(seq_len, n_hidden) :\n",
        "        All alpha values found for each sample\n",
        "    '''\n",
        "    seq_len = len(obs_seq)\n",
        "\n",
        "    if length is None:\n",
        "        length = seq_len\n",
        "\n",
        "    trans_mat, obs_mat, init_dist = params.trans_mat, params.obs_mat, params.init_dist\n",
        "\n",
        "    trans_mat = jnp.array(trans_mat)\n",
        "    obs_mat = jnp.array(obs_mat)\n",
        "    init_dist = jnp.array(init_dist)\n",
        "\n",
        "    n_states, n_obs = obs_mat.shape\n",
        "\n",
        "    def scan_fn(carry, t):\n",
        "        (alpha_prev, log_ll_prev) = carry\n",
        "        alpha_n = jnp.where(t < length,\n",
        "                            obs_mat[:, obs_seq[t]] * (alpha_prev[:, None] * trans_mat).sum(axis=0),\n",
        "                            jnp.zeros_like(alpha_prev))\n",
        "\n",
        "        alpha_n, cn = normalize(alpha_n)\n",
        "        carry = (alpha_n, jnp.log(cn) + log_ll_prev)\n",
        "\n",
        "        return carry, alpha_n\n",
        "\n",
        "    # initial belief state\n",
        "    alpha_0, c0 = normalize(init_dist * obs_mat[:, obs_seq[0]])\n",
        "\n",
        "    # setup scan loop\n",
        "    init_state = (alpha_0, jnp.log(c0))\n",
        "    ts = jnp.arange(1, seq_len)\n",
        "    carry, alpha_hist = lax.scan(scan_fn, init_state, ts)\n",
        "\n",
        "    # post-process\n",
        "    alpha_hist = jnp.vstack([alpha_0.reshape(1, n_states), alpha_hist])\n",
        "    (alpha_final, log_ll) = carry\n",
        "    return log_ll, alpha_hist\n",
        "\n",
        "\n",
        "@jit\n",
        "def hmm_loglikelihood_jax(params, observations, lens):\n",
        "    '''\n",
        "    Finds the loglikelihood of each observation sequence parallel using vmap.\n",
        "    Parameters\n",
        "    ----------\n",
        "    params : HMMJax\n",
        "        Hidden Markov Model\n",
        "    observations: array(N, seq_len)\n",
        "        Batch of observation sequences\n",
        "    lens : array(N, seq_len)\n",
        "        Consists of the valid length of each observation sequence\n",
        "    Returns\n",
        "    -------\n",
        "    * array(N, seq_len)\n",
        "        Consists of the loglikelihood of each observation sequence\n",
        "    '''\n",
        "\n",
        "    def forward_(params, x, length):\n",
        "        return hmm_forwards_jax(params, x, length)[0]\n",
        "\n",
        "    return vmap(forward_, in_axes=(None, 0, 0))(params, observations, lens)\n",
        "\n",
        "\n",
        "def hmm_backwards_jax(params, obs_seq, length=None):\n",
        "    '''\n",
        "    Computes the backwards probabilities\n",
        "    Parameters\n",
        "    ----------\n",
        "    params : HMMJax\n",
        "        Hidden Markov Model\n",
        "    obs_seq: array(seq_len,)\n",
        "        History of observable events\n",
        "    length : array(seq_len,)\n",
        "        The valid length of the observation sequence\n",
        "    Returns\n",
        "    -------\n",
        "    * array(seq_len, n_states)\n",
        "       Beta values\n",
        "    '''\n",
        "    seq_len = len(obs_seq)\n",
        "\n",
        "    if length is None:\n",
        "        length = seq_len\n",
        "\n",
        "    trans_mat, obs_mat, init_dist = params.trans_mat, params.obs_mat, params.init_dist\n",
        "\n",
        "    trans_mat = jnp.array(trans_mat)\n",
        "    obs_mat = jnp.array(obs_mat)\n",
        "    init_dist = jnp.array(init_dist)\n",
        "\n",
        "    n_states, n_obs = obs_mat.shape\n",
        "\n",
        "    beta_t = jnp.ones((n_states,))\n",
        "\n",
        "    def scan_fn(beta_prev, t):\n",
        "        beta_t = jnp.where(t > length,\n",
        "                           jnp.zeros_like(beta_prev),\n",
        "                           normalize((beta_prev * obs_mat[:, obs_seq[-t + 1]] * trans_mat).sum(axis=1))[0])\n",
        "        return beta_t, beta_t\n",
        "\n",
        "    ts = jnp.arange(2, seq_len + 1)\n",
        "    _, beta_hist = lax.scan(scan_fn, beta_t, ts)\n",
        "\n",
        "    beta_hist = jnp.flip(jnp.vstack([beta_t.reshape(1, n_states), beta_hist]), axis=0)\n",
        "\n",
        "    return beta_hist\n",
        "\n",
        "\n",
        "def hmm_forwards_backwards_jax(params, obs_seq, length=None):\n",
        "    '''\n",
        "    Computes, for each time step, the marginal conditional probability that the Hidden Markov Model was\n",
        "    in each possible state given the observations that were made at each time step, i.e.\n",
        "    P(z[i] | x[0], ..., x[num_steps - 1]) for all i from 0 to num_steps - 1\n",
        "    Parameters\n",
        "    ----------\n",
        "    params : HMMJax\n",
        "        Hidden Markov Model\n",
        "    obs_seq: array(seq_len)\n",
        "        History of observed states\n",
        "    Returns\n",
        "    -------\n",
        "    * array(seq_len, n_states)\n",
        "        Alpha values\n",
        "    * array(seq_len, n_states)\n",
        "        Beta values\n",
        "    * array(seq_len, n_states)\n",
        "        Marginal conditional probability\n",
        "    * float\n",
        "        The loglikelihood giving log(p(x|model))\n",
        "    '''\n",
        "    seq_len = len(obs_seq)\n",
        "    if length is None:\n",
        "        length = seq_len\n",
        "\n",
        "    def gamma_t(t):\n",
        "        gamma_t = jnp.where(t < length,\n",
        "                            alpha[t] * beta[t - length],\n",
        "                            jnp.zeros((n_states,)))\n",
        "        return gamma_t\n",
        "\n",
        "    ll, alpha = hmm_forwards_jax(params, obs_seq, length)\n",
        "    n_states = alpha.shape[1]\n",
        "\n",
        "    beta = hmm_backwards_jax(params, obs_seq, length)\n",
        "\n",
        "    ts = jnp.arange(seq_len)\n",
        "    gamma = vmap(gamma_t, (0))(ts)\n",
        "    # gamma = alpha * jnp.roll(beta, -seq_len + length, axis=0) #: Alternative\n",
        "    gamma = vmap(lambda x: normalize(x)[0])(gamma)\n",
        "    return alpha, beta, gamma, ll\n"
      ],
      "metadata": {
        "id": "1qLvsJy1X_TM"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below are my contributions\n"
      ],
      "metadata": {
        "id": "bqQdk3pUzh-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@flax.struct.dataclass\n",
        "class HMMWithActionJax:\n",
        "    trans_mat: jnp.array  # A : (n_actions, n_states, n_states)\n",
        "    obs_mat: jnp.array  # B : (n_states, n_obs)\n",
        "    init_dist: jnp.array  # pi : (n_states)"
      ],
      "metadata": {
        "id": "j-ePHPODWbgo"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "QDJ7YcaZGSTI"
      },
      "outputs": [],
      "source": [
        "# Naive (un-vectorized) version\n",
        "@partial(jax.jit, static_argnums=(1))\n",
        "def fixed_lag_smoother(params, win_len, alpha_win, obs_seq_win, obs, act=None):\n",
        "    '''\n",
        "    Description...\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    params      : HMMJax\n",
        "        Hidden Markov Model (with action-dependent transition)\n",
        "    win_len     : int\n",
        "        Desired window length (>= 2)\n",
        "    alpha_win   : array\n",
        "        Alpha values for the most recent win_len steps, excluding current step\n",
        "    obs_seq_win : array\n",
        "        Observations for the most recent win_len steps, excluding current step\n",
        "    obs         : int\n",
        "        New observation for the current step\n",
        "    act         : array\n",
        "        (optional) Actions for the most recent win_len steps, including current step\n",
        "    Returns\n",
        "    -------\n",
        "    * array(win_len, n_states)\n",
        "        Updated alpha values\n",
        "    * array(win_len)\n",
        "        Updated observations for the past d steps\n",
        "    * array(win_len, n_states)\n",
        "        Smoothed posteriors for the past d steps\n",
        "\n",
        "    '''\n",
        "    if len(alpha_win.shape) < 2:\n",
        "        alpha_win = jnp.expand_dims(alpha_win, axis=0)\n",
        "    curr_len = alpha_win.shape[0]\n",
        "    win_len = min(win_len, curr_len+1)\n",
        "    assert win_len >= 2, \"Must keep a window of length at least 2.\"\n",
        "\n",
        "    trans_mat, obs_mat = params.trans_mat, params.obs_mat\n",
        "    n_states, n_obs = obs_mat.shape\n",
        "    \n",
        "    # If trans_mat is independent of action, adjust shape\n",
        "    if len(trans_mat.shape) < 3:\n",
        "        trans_mat = jnp.expand_dims(trans_mat, axis=0)\n",
        "        act = None\n",
        "    if act is None:\n",
        "        act = jnp.zeros(shape=(curr_len+1,), dtype=jnp.int8)\n",
        "\n",
        "    # Shift window forward by 1\n",
        "    if curr_len == win_len:\n",
        "        alpha_win = alpha_win[1:]\n",
        "        obs_seq_win = obs_seq_win[1:]\n",
        "    new_alpha, _ = normalize(\n",
        "        obs_mat[:, obs] * (alpha_win[-1][:, None] * trans_mat[act[-1]]).sum(axis=0)\n",
        "    )\n",
        "    alpha_win = jnp.concatenate((alpha_win, new_alpha[None, :]), axis=0)\n",
        "    obs_seq_win = jnp.append(obs_seq_win, obs)\n",
        "\n",
        "    # Smooth backwards inside the window\n",
        "    beta_win = jnp.ones(shape=(win_len, n_states))\n",
        "    gamma_win = jnp.array(alpha_win)\n",
        "    for t in range(win_len-2, -1, -1):\n",
        "        new_beta, _ = normalize(\n",
        "            (beta_win[t+1,:] * obs_mat[:, obs_seq_win[t+1]] *\n",
        "             trans_mat[act[t]]).sum(axis=1)\n",
        "        )\n",
        "        beta_win = beta_win.at[t, :].set(new_beta)\n",
        "\n",
        "        new_gamma, _ = normalize(alpha_win[t, :]*beta_win[t, :])\n",
        "        gamma_win = gamma_win.at[t, :].set(new_gamma)\n",
        "    return alpha_win, obs_seq_win, beta_win, gamma_win"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorized version\n",
        "@partial(jax.jit, static_argnums=(1))\n",
        "def fixed_lag_smoother_vectorized(params, win_len, alpha_win, bmatrix_win, obs, act=None):\n",
        "    '''\n",
        "    Description...\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    params      : HMMJax\n",
        "        Hidden Markov Model (with action-dependent transition)\n",
        "    win_len     : int\n",
        "        Desired window length (>= 2)\n",
        "    alpha_win   : array\n",
        "        Alpha values for the most recent win_len steps, excluding current step\n",
        "    bmatrix_win   : array\n",
        "        Beta transformations for the most recent win_len steps, excluding current step\n",
        "    obs         : int\n",
        "        New observation for the current step\n",
        "    act         : array\n",
        "        (optional) Actions for the most recent win_len steps, including current step\n",
        "    Returns\n",
        "    -------\n",
        "    * array(win_len, n_states)\n",
        "        Updated alpha values\n",
        "    * array(win_len, n_states)\n",
        "        Updated beta transformations\n",
        "    * array(win_len, n_states)\n",
        "        Smoothed posteriors for the past d steps\n",
        "    '''\n",
        "    if len(alpha_win.shape) < 2:\n",
        "        alpha_win = jnp.expand_dims(alpha_win, axis=0)\n",
        "    curr_len = alpha_win.shape[0]\n",
        "    win_len = min(win_len, curr_len+1)\n",
        "    assert win_len >= 2, \"Must keep a window of length at least 2.\"\n",
        "\n",
        "    trans_mat, obs_mat = params.trans_mat, params.obs_mat\n",
        "    n_states, n_obs = obs_mat.shape\n",
        "    \n",
        "    # If trans_mat is independent of action, adjust shape\n",
        "    if len(trans_mat.shape) < 3:\n",
        "        trans_mat = jnp.expand_dims(trans_mat, axis=0)\n",
        "        act = None\n",
        "    if act is None:\n",
        "        act = jnp.zeros(shape=(curr_len+1,), dtype=jnp.int8)\n",
        "\n",
        "    # Shift window forward by 1\n",
        "    if curr_len == win_len:\n",
        "        alpha_win = alpha_win[1:]\n",
        "        bmatrix_win = bmatrix_win[1:]\n",
        "    # Perform one forward operation\n",
        "    new_alpha, _ = normalize(\n",
        "        obs_mat[:, obs] * (alpha_win[-1][:, None] * trans_mat[act[-1]]).sum(axis=0)\n",
        "    )\n",
        "    alpha_win = jnp.concatenate((alpha_win, new_alpha[None, :]))\n",
        "    # Smooth inside the window in parallel\n",
        "    def update_bmatrix(bmatrix):\n",
        "        return (bmatrix @ trans_mat[act[-2]]) * obs_mat[:, obs]\n",
        "    bmatrix_win = vmap(update_bmatrix)(bmatrix_win)\n",
        "    bmatrix_win = jnp.concatenate((bmatrix_win, jnp.eye(n_states)[None, :]))\n",
        "    # Compute beta values by row-summing bmatrices\n",
        "    def get_beta(bmatrix):\n",
        "        return normalize(bmatrix.sum(axis=1))[0]\n",
        "    beta_win = vmap(get_beta)(bmatrix_win)\n",
        "    gamma_win, _ = normalize(alpha_win * beta_win, axis=1)\n",
        "\n",
        "    return alpha_win, bmatrix_win, gamma_win"
      ],
      "metadata": {
        "id": "6YFXqHP00UmQ"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Umbrella-rain toy example (AI, A Modern Approach)\n",
        "data = jnp.array([0, 0, 1, 1, 1])\n",
        "transmat = jnp.array([[0.7, 0.3], [0.3, 0.7]])\n",
        "obsmat = jnp.array([[0.9, 0.1], [0.2, 0.8]])\n",
        "prior = jnp.array([0.5, 0.5])\n",
        "\n",
        "hmm = HMMJax(trans_mat=transmat, obs_mat=obsmat, init_dist=prior)"
      ],
      "metadata": {
        "id": "VfXolxcdoyZW"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Larger-scale example for time experiments\n",
        "key = PRNGKey(0)\n",
        "data = jax.random.choice(key, 2, shape=(1000000,))"
      ],
      "metadata": {
        "id": "-XgqOd8FpK07"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_fixed_lag_smoother_result(params, win_len, data, prior, act=None):\n",
        "    assert data.size > 2, \"Complete observation set must be of size at least 2\"\n",
        "    alpha, _ = normalize(jnp.multiply(prior, obsmat[:, data[0]]))\n",
        "    obs_seq = jnp.array([data[0]])\n",
        "    for obs in data[1:]:\n",
        "        alpha, obs_seq, beta, gamma = fixed_lag_smoother(hmm, win_len, alpha, obs_seq, obs)\n",
        "    return alpha, beta, gamma"
      ],
      "metadata": {
        "id": "PIFlEVelxbIt"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_fixed_lag_smoother_result_vectorized(params, win_len, data, prior, act=None):\n",
        "    assert data.size > 2, \"Complete observation set must be of size at least 2\"\n",
        "    trans_mat, obs_mat = params.trans_mat, params.obs_mat\n",
        "    n_states, n_obs = obs_mat.shape\n",
        "    alpha, _ = normalize(jnp.multiply(prior, obsmat[:, data[0]]))\n",
        "    bmatrix = jnp.eye(n_states)[None, :]\n",
        "    obs_seq = jnp.array([data[0]])\n",
        "    for obs in data[1:]:\n",
        "        alpha, bmatrix, gamma = fixed_lag_smoother_vectorized(hmm, win_len, alpha, bmatrix, obs)\n",
        "    return alpha, beta, gamma"
      ],
      "metadata": {
        "id": "DE-GHyHs6vqL"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "*_, gamma = get_fixed_lag_smoother_result(hmm, 3000, data, prior)"
      ],
      "metadata": {
        "id": "_oQSyRtPOPvI",
        "outputId": "cb1dab32-8057-4f3c-facc-8c940252b22f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-190-63d583ede344>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timeit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*_, gamma = get_fixed_lag_smoother_result(hmm, 3000, data, prior)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-52>\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0mnumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1057\u001b[0;31m                 \u001b[0mtime_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1058\u001b[0m                 \u001b[0mworst_tuning\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworst_tuning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
            "\u001b[0;32m<ipython-input-188-ee2bb04e1f70>\u001b[0m in \u001b[0;36mget_fixed_lag_smoother_result\u001b[0;34m(params, win_len, data, prior, act)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mobs_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mobs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfixed_lag_smoother\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhmm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwin_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/traceback_util.py\u001b[0m in \u001b[0;36mreraise_with_filtered_traceback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m       \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltering_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36mcache_miss\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0mflat_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs_flat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_fun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         donated_invars=donated_invars, inline=inline)\n\u001b[0m\u001b[1;32m    436\u001b[0m     \u001b[0mout_pytree_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_pytree_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, fun, *args, **params)\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1708\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1709\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_bind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_bind_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mcall_bind\u001b[0;34m(primitive, fun, *args, **params)\u001b[0m\n\u001b[1;32m   1719\u001b[0m       fun, primitive, top_trace and top_trace.level, tuple(params.items()))\n\u001b[1;32m   1720\u001b[0m   \u001b[0mtracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1721\u001b[0;31m   \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1722\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_todos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_trace_todo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mprocess_call\u001b[0;34m(self, primitive, f, tracers, params)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m   \u001b[0mprocess_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/dispatch.py\u001b[0m in \u001b[0;36m_xla_call_impl\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    141\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0minline\u001b[0m  \u001b[0;31m# Only used at tracing time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m   compiled_fun = _xla_callable(fun, device, backend, name, donated_invars,\n\u001b[0;32m--> 143\u001b[0;31m                                *unsafe_map(arg_spec, args))\n\u001b[0m\u001b[1;32m    144\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiled_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/linear_util.py\u001b[0m in \u001b[0;36mmemoized_fun\u001b[0;34m(fun, *args)\u001b[0m\n\u001b[1;32m    270\u001b[0m       \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpopulate_stores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m       \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m       \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/dispatch.py\u001b[0m in \u001b[0;36m_xla_callable_uncached\u001b[0;34m(fun, device, backend, name, donated_invars, *arg_specs)\u001b[0m\n\u001b[1;32m    168\u001b[0m                            donated_invars, *arg_specs):\n\u001b[1;32m    169\u001b[0m   return lower_xla_callable(fun, device, backend, name, donated_invars,\n\u001b[0;32m--> 170\u001b[0;31m                             *arg_specs).compile().unsafe_call\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0m_xla_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_xla_callable_uncached\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/dispatch.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    527\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         self._executable = XlaCompiledComputation.from_xla_computation(\n\u001b[0;32m--> 529\u001b[0;31m             self.name, self._hlo, **self.compile_args)\n\u001b[0m\u001b[1;32m    530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_executable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/dispatch.py\u001b[0m in \u001b[0;36mfrom_xla_computation\u001b[0;34m(name, xla_computation, nreps, device, backend, tuple_args, in_avals, out_avals, kept_var_idx)\u001b[0m\n\u001b[1;32m    612\u001b[0m     with log_elapsed_time(f\"Finished XLA compilation of {name} \"\n\u001b[1;32m    613\u001b[0m                           \"in {elapsed_time} sec\"):\n\u001b[0;32m--> 614\u001b[0;31m       \u001b[0mcompiled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompile_or_get_cached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxla_computation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m     buffer_counts = (None if len(out_avals) == 1 else\n\u001b[1;32m    616\u001b[0m                      [aval_to_num_buffers(aval) for aval in out_avals])\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/dispatch.py\u001b[0m in \u001b[0;36mcompile_or_get_cached\u001b[0;34m(backend, computation, compile_options)\u001b[0m\n\u001b[1;32m    581\u001b[0m               else computation.as_hlo_text())\n\u001b[1;32m    582\u001b[0m     \u001b[0m_dump_ir_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mir_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mbackend_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomputation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/profiler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mTraceAnnotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdecorator_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/dispatch.py\u001b[0m in \u001b[0;36mbackend_compile\u001b[0;34m(backend, built_c, options)\u001b[0m\n\u001b[1;32m    535\u001b[0m   \u001b[0;31m# we use a separate function call to ensure that XLA compilation appears\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m   \u001b[0;31m# separately in Python profiling results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 537\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuilt_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;31m# TODO(phawkins): update users.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "*_, gamma_vec = get_fixed_lag_smoother_result_vectorized(hmm, 3000, data, prior)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16uvHHTQ8L2_",
        "outputId": "5f65751b-9951-4d39-8d32-15e0edc2008f"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 4.12 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "1 loop, best of 5: 156 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "_, _, g, _ = hmm_forwards_backwards_jax(hmm, data)\n",
        "print(g)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Y7D4me5CGlL",
        "outputId": "ea2d086d-94a8-4a85-e3c7-e8feaa6c2967"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.6852272  0.3147728 ]\n",
            " [0.104872   0.8951281 ]\n",
            " [0.08992866 0.9100713 ]\n",
            " [0.51482636 0.48517358]\n",
            " [0.08724132 0.9127587 ]\n",
            " [0.09187889 0.9081211 ]\n",
            " [0.56770897 0.43229103]\n",
            " [0.24101867 0.7589813 ]\n",
            " [0.80832404 0.19167593]\n",
            " [0.8642606  0.13573939]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "key = PRNGKey(0)\n",
        "num_states = 3\n",
        "num_obs = 5\n",
        "num_timesteps = 15\n",
        "\n",
        "data = jax.random.choice(key, num_obs, (num_timesteps,))\n",
        "key, _ = split(key)\n",
        "\n",
        "transmat = jax.random.uniform(key, shape=(num_states, num_states))\n",
        "transmat, _ = normalize(transmat, axis=1)\n",
        "print(transmat)\n",
        "key, _ = split(key)\n",
        "\n",
        "obsmat = jax.random.uniform(key, shape=(num_states, num_obs))\n",
        "obsmat, _ = normalize(obsmat, axis=1)\n",
        "print(obsmat)\n",
        "key, _ = split(key)\n",
        "\n",
        "prior = jnp.array([0.33, 0.33, 0.34])"
      ],
      "metadata": {
        "id": "7W7oRPpIz5-R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}