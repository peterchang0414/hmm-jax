{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fixed_lag_smoother.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peterchang0414/hmm-jax/blob/main/fixed_lag_smoother.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q flax"
      ],
      "metadata": {
        "id": "vR05NbgRYED1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a044872-f7bd-4834-f22f-4134402f174a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |█▉                              | 10 kB 28.2 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 20 kB 29.4 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 30 kB 34.2 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 40 kB 39.0 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 51 kB 35.1 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 61 kB 37.8 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 71 kB 27.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 81 kB 27.6 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 92 kB 29.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 102 kB 31.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 112 kB 31.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 122 kB 31.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 133 kB 31.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 143 kB 31.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 153 kB 31.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 163 kB 31.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 174 kB 31.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 184 kB 31.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 140 kB 50.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 72 kB 656 kB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference and learning code for Hidden Markov Models using discrete observations.\n",
        "# Has Jax version of each function. For the Numpy version, please see hmm_numpy_lib.py\n",
        "# The Jax version of inference (not learning)\n",
        "# has been upstreamed to https://github.com/deepmind/distrax/blob/master/distrax/_src/utils/hmm.py.\n",
        "# This version is kept for historical purposes.\n",
        "# Author: Gerardo Duran-Martin (@gerdm), Aleyna Kara (@karalleyna), Kevin Murphy (@murphyk)\n",
        "\n",
        "from jax import lax\n",
        "from jax.scipy.special import logit\n",
        "from functools import partial\n",
        "\n",
        "import jax.numpy as jnp\n",
        "from scipy.special import softmax\n",
        "from jax import vmap\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import jax\n",
        "import itertools\n",
        "from jax import jit\n",
        "from jax.nn import softmax\n",
        "from jax.random import PRNGKey, split, normal\n",
        "from jax.random import split, randint, PRNGKey, normal, permutation\n",
        "\n",
        "import flax\n",
        "\n",
        "'''\n",
        "Hidden Markov Model class used in jax implementations of inference algorithms.\n",
        "The functions of optimizers expect that the type of its parameters \n",
        "is pytree. So, they cannot work on a vanilla dataclass. To see more:\n",
        "                https://github.com/google/jax/issues/2371\n",
        "Since the flax.dataclass is registered pytree beforehand, it facilitates to use\n",
        "jit, vmap and optimizers on the hidden markov model.\n",
        "'''\n",
        "\n",
        "\n",
        "@flax.struct.dataclass\n",
        "class HMMJax:\n",
        "    trans_mat: jnp.array  # A : (n_states, n_states)\n",
        "    obs_mat: jnp.array  # B : (n_states, n_obs)\n",
        "    init_dist: jnp.array  # pi : (n_states)\n",
        "\n",
        "\n",
        "def normalize(u, axis=0, eps=1e-15):\n",
        "    '''\n",
        "    Normalizes the values within the axis in a way that they sum up to 1.\n",
        "    Parameters\n",
        "    ----------\n",
        "    u : array\n",
        "    axis : int\n",
        "    eps : float\n",
        "        Threshold for the alpha values\n",
        "    Returns\n",
        "    -------\n",
        "    * array\n",
        "        Normalized version of the given matrix\n",
        "    * array(seq_len, n_hidden) :\n",
        "        The values of the normalizer\n",
        "    '''\n",
        "    u = jnp.where(u == 0, 0, jnp.where(u < eps, eps, u))\n",
        "    c = u.sum(axis=axis, keepdims=True)\n",
        "    c = jnp.where(c == 0, 1, c)\n",
        "    return u / c, c\n",
        "\n",
        "\n",
        "##############################\n",
        "# Inference\n",
        "\n",
        "def hmm_forwards_jax(params, obs_seq, length=None):\n",
        "    '''\n",
        "    Calculates a belief state\n",
        "    Parameters\n",
        "    ----------\n",
        "    params : HMMJax\n",
        "        Hidden Markov Model\n",
        "    obs_seq: array(seq_len)\n",
        "        History of observable events\n",
        "    Returns\n",
        "    -------\n",
        "    * float\n",
        "        The loglikelihood giving log(p(x|model))\n",
        "    * array(seq_len, n_hidden) :\n",
        "        All alpha values found for each sample\n",
        "    '''\n",
        "    seq_len = len(obs_seq)\n",
        "\n",
        "    if length is None:\n",
        "        length = seq_len\n",
        "\n",
        "    trans_mat, obs_mat, init_dist = params.trans_mat, params.obs_mat, params.init_dist\n",
        "\n",
        "    trans_mat = jnp.array(trans_mat)\n",
        "    obs_mat = jnp.array(obs_mat)\n",
        "    init_dist = jnp.array(init_dist)\n",
        "\n",
        "    n_states, n_obs = obs_mat.shape\n",
        "\n",
        "    def scan_fn(carry, t):\n",
        "        (alpha_prev, log_ll_prev) = carry\n",
        "        alpha_n = jnp.where(t < length,\n",
        "                            obs_mat[:, obs_seq[t]] * (alpha_prev[:, None] * trans_mat).sum(axis=0),\n",
        "                            jnp.zeros_like(alpha_prev))\n",
        "\n",
        "        alpha_n, cn = normalize(alpha_n)\n",
        "        carry = (alpha_n, jnp.log(cn) + log_ll_prev)\n",
        "\n",
        "        return carry, alpha_n\n",
        "\n",
        "    # initial belief state\n",
        "    alpha_0, c0 = normalize(init_dist * obs_mat[:, obs_seq[0]])\n",
        "\n",
        "    # setup scan loop\n",
        "    init_state = (alpha_0, jnp.log(c0))\n",
        "    ts = jnp.arange(1, seq_len)\n",
        "    carry, alpha_hist = lax.scan(scan_fn, init_state, ts)\n",
        "\n",
        "    # post-process\n",
        "    alpha_hist = jnp.vstack([alpha_0.reshape(1, n_states), alpha_hist])\n",
        "    (alpha_final, log_ll) = carry\n",
        "    return log_ll, alpha_hist\n",
        "\n",
        "\n",
        "@jit\n",
        "def hmm_loglikelihood_jax(params, observations, lens):\n",
        "    '''\n",
        "    Finds the loglikelihood of each observation sequence parallel using vmap.\n",
        "    Parameters\n",
        "    ----------\n",
        "    params : HMMJax\n",
        "        Hidden Markov Model\n",
        "    observations: array(N, seq_len)\n",
        "        Batch of observation sequences\n",
        "    lens : array(N, seq_len)\n",
        "        Consists of the valid length of each observation sequence\n",
        "    Returns\n",
        "    -------\n",
        "    * array(N, seq_len)\n",
        "        Consists of the loglikelihood of each observation sequence\n",
        "    '''\n",
        "\n",
        "    def forward_(params, x, length):\n",
        "        return hmm_forwards_jax(params, x, length)[0]\n",
        "\n",
        "    return vmap(forward_, in_axes=(None, 0, 0))(params, observations, lens)\n",
        "\n",
        "\n",
        "def hmm_backwards_jax(params, obs_seq, length=None):\n",
        "    '''\n",
        "    Computes the backwards probabilities\n",
        "    Parameters\n",
        "    ----------\n",
        "    params : HMMJax\n",
        "        Hidden Markov Model\n",
        "    obs_seq: array(seq_len,)\n",
        "        History of observable events\n",
        "    length : array(seq_len,)\n",
        "        The valid length of the observation sequence\n",
        "    Returns\n",
        "    -------\n",
        "    * array(seq_len, n_states)\n",
        "       Beta values\n",
        "    '''\n",
        "    seq_len = len(obs_seq)\n",
        "\n",
        "    if length is None:\n",
        "        length = seq_len\n",
        "\n",
        "    trans_mat, obs_mat, init_dist = params.trans_mat, params.obs_mat, params.init_dist\n",
        "\n",
        "    trans_mat = jnp.array(trans_mat)\n",
        "    obs_mat = jnp.array(obs_mat)\n",
        "    init_dist = jnp.array(init_dist)\n",
        "\n",
        "    n_states, n_obs = obs_mat.shape\n",
        "\n",
        "    beta_t = jnp.ones((n_states,))\n",
        "\n",
        "    def scan_fn(beta_prev, t):\n",
        "        beta_t = jnp.where(t > length,\n",
        "                           jnp.zeros_like(beta_prev),\n",
        "                           normalize((beta_prev * obs_mat[:, obs_seq[-t + 1]] * trans_mat).sum(axis=1))[0])\n",
        "        return beta_t, beta_t\n",
        "\n",
        "    ts = jnp.arange(2, seq_len + 1)\n",
        "    _, beta_hist = lax.scan(scan_fn, beta_t, ts)\n",
        "\n",
        "    beta_hist = jnp.flip(jnp.vstack([beta_t.reshape(1, n_states), beta_hist]), axis=0)\n",
        "\n",
        "    return beta_hist\n",
        "\n",
        "\n",
        "def hmm_forwards_backwards_jax(params, obs_seq, length=None):\n",
        "    '''\n",
        "    Computes, for each time step, the marginal conditional probability that the Hidden Markov Model was\n",
        "    in each possible state given the observations that were made at each time step, i.e.\n",
        "    P(z[i] | x[0], ..., x[num_steps - 1]) for all i from 0 to num_steps - 1\n",
        "    Parameters\n",
        "    ----------\n",
        "    params : HMMJax\n",
        "        Hidden Markov Model\n",
        "    obs_seq: array(seq_len)\n",
        "        History of observed states\n",
        "    Returns\n",
        "    -------\n",
        "    * array(seq_len, n_states)\n",
        "        Alpha values\n",
        "    * array(seq_len, n_states)\n",
        "        Beta values\n",
        "    * array(seq_len, n_states)\n",
        "        Marginal conditional probability\n",
        "    * float\n",
        "        The loglikelihood giving log(p(x|model))\n",
        "    '''\n",
        "    seq_len = len(obs_seq)\n",
        "    if length is None:\n",
        "        length = seq_len\n",
        "\n",
        "    def gamma_t(t):\n",
        "        gamma_t = jnp.where(t < length,\n",
        "                            alpha[t] * beta[t - length],\n",
        "                            jnp.zeros((n_states,)))\n",
        "        return gamma_t\n",
        "\n",
        "    ll, alpha = hmm_forwards_jax(params, obs_seq, length)\n",
        "    n_states = alpha.shape[1]\n",
        "\n",
        "    beta = hmm_backwards_jax(params, obs_seq, length)\n",
        "\n",
        "    ts = jnp.arange(seq_len)\n",
        "    gamma = vmap(gamma_t, (0))(ts)\n",
        "    # gamma = alpha * jnp.roll(beta, -seq_len + length, axis=0) #: Alternative\n",
        "    gamma = vmap(lambda x: normalize(x)[0])(gamma)\n",
        "    return alpha, beta, gamma, ll\n"
      ],
      "metadata": {
        "id": "1qLvsJy1X_TM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key = PRNGKey(0)\n",
        "num_states = 3\n",
        "num_obs = 5\n",
        "num_timesteps = 15\n",
        "\n",
        "data = jax.random.choice(key, num_obs, (num_timesteps,))\n",
        "key, _ = split(key)\n",
        "\n",
        "transmat = jax.random.uniform(key, shape=(num_states, num_states))\n",
        "transmat, _ = normalize(transmat, axis=1)\n",
        "print(transmat)\n",
        "key, _ = split(key)\n",
        "\n",
        "obsmat = jax.random.uniform(key, shape=(num_states, num_obs))\n",
        "obsmat, _ = normalize(obsmat, axis=1)\n",
        "print(obsmat)\n",
        "key, _ = split(key)\n",
        "\n",
        "prior = jnp.array([0.33, 0.33, 0.34])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_gmzavAdPCb",
        "outputId": "87aed4a5-20d8-44fa-e01a-6625aa5ba209"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.00327667 0.372277   0.62444633]\n",
            " [0.03723689 0.5034511  0.459312  ]\n",
            " [0.38789576 0.27844316 0.33366108]]\n",
            "[[0.19659741 0.04710761 0.2822843  0.16964358 0.30436713]\n",
            " [0.26830336 0.08532328 0.22020769 0.18710755 0.23905815]\n",
            " [0.1802366  0.16051903 0.21636975 0.33137584 0.11149877]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Umbrella-rain toy example (AI, A Modern Approach)\n",
        "data = jnp.array([0, 0, 1, 1, 1])\n",
        "transmat = jnp.array([[0.7, 0.3], [0.3, 0.7]])\n",
        "obsmat = jnp.array([[0.9, 0.1], [0.2, 0.8]])\n",
        "prior = jnp.array([0.5, 0.5])\n",
        "\n",
        "hmm = HMMJax(trans_mat=transmat, obs_mat=obsmat, init_dist=prior)\n",
        "\n",
        "print(hmm_forwards_backwards_jax(hmm, data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWasAdRldQh9",
        "outputId": "e8141aec-7e79-4423-d19c-19608c8d26ad"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(DeviceArray([[0.81818175, 0.18181819],\n",
            "             [0.88335705, 0.11664297],\n",
            "             [0.19066793, 0.8093321 ],\n",
            "             [0.07011891, 0.92988104],\n",
            "             [0.05751521, 0.94248486]], dtype=float32), DeviceArray([[0.5727641 , 0.42723584],\n",
            "             [0.32267347, 0.6773265 ],\n",
            "             [0.32465208, 0.67534786],\n",
            "             [0.34444445, 0.65555555],\n",
            "             [1.        , 1.        ]], dtype=float32), DeviceArray([[0.8578096 , 0.14219043],\n",
            "             [0.7829768 , 0.21702313],\n",
            "             [0.10172988, 0.89827013],\n",
            "             [0.03811033, 0.9618896 ],\n",
            "             [0.0575152 , 0.94248474]], dtype=float32), DeviceArray([-3.300516], dtype=float32))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@flax.struct.dataclass\n",
        "class HMMWithActionJax:\n",
        "    trans_mat: jnp.array  # A : (n_actions, n_states, n_states)\n",
        "    obs_mat: jnp.array  # B : (n_states, n_obs)\n",
        "    init_dist: jnp.array  # pi : (n_states)"
      ],
      "metadata": {
        "id": "j-ePHPODWbgo"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QDJ7YcaZGSTI"
      },
      "outputs": [],
      "source": [
        "def fixed_lag_smoother(params, alpha_win, obs_seq_win, obs, act=None):\n",
        "    '''\n",
        "    Description...\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    params : HMMWithActionJax\n",
        "        Hidden Markov Model (with action-dependent transition)\n",
        "    alpha_win   : array\n",
        "        Alpha values for the most recent window, excluding current step\n",
        "    obs_seq_win : array\n",
        "        Observations for the most recent window, excluding current step\n",
        "    obs         : int\n",
        "        New observation for the current step\n",
        "    act         : array\n",
        "        (optional) Actions for the most recent window, including current step\n",
        "    Returns\n",
        "    -------\n",
        "    * array(win_len, n_states)\n",
        "        Updated alpha values\n",
        "    * array(win_len)\n",
        "        Updated observations for the past d steps\n",
        "    * array(win_len, n_states)\n",
        "        Smoothed posteriors for the past d steps\n",
        "    * float\n",
        "        The loglikelihood of the past d steps\n",
        "    '''\n",
        "    trans_mat, obs_mat = params.trans_mat, params.obs_mat\n",
        "    n_states, n_obs = obs_mat.shape\n",
        "\n",
        "    assert alpha_win.shape[1] < 2,\"Must keep a window of length at least 2.\"\n",
        "    \n",
        "    if act is None:\n",
        "        act = jnp.ones(shape=(1, ))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SOG_0KledIlk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}