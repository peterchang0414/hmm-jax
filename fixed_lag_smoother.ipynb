{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fixed_lag_smoother.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peterchang0414/hmm-jax/blob/main/fixed_lag_smoother.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q flax"
      ],
      "metadata": {
        "id": "vR05NbgRYED1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50a59373-3824-4b78-b7b8-e66d010f14a6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 184 kB 6.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 140 kB 12.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 72 kB 604 kB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference and learning code for Hidden Markov Models using discrete observations.\n",
        "# Has Jax version of each function. For the Numpy version, please see hmm_numpy_lib.py\n",
        "# The Jax version of inference (not learning)\n",
        "# has been upstreamed to https://github.com/deepmind/distrax/blob/master/distrax/_src/utils/hmm.py.\n",
        "# This version is kept for historical purposes.\n",
        "# Author: Gerardo Duran-Martin (@gerdm), Aleyna Kara (@karalleyna), Kevin Murphy (@murphyk)\n",
        "\n",
        "from jax import lax\n",
        "from jax.scipy.special import logit\n",
        "from functools import partial\n",
        "\n",
        "import jax.numpy as jnp\n",
        "from scipy.special import softmax\n",
        "from jax import vmap\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import jax\n",
        "import itertools\n",
        "from jax import jit\n",
        "from jax.nn import softmax\n",
        "from jax.random import PRNGKey, split, normal\n",
        "from jax.random import split, randint, PRNGKey, normal, permutation\n",
        "\n",
        "import flax\n",
        "\n",
        "'''\n",
        "Hidden Markov Model class used in jax implementations of inference algorithms.\n",
        "The functions of optimizers expect that the type of its parameters \n",
        "is pytree. So, they cannot work on a vanilla dataclass. To see more:\n",
        "                https://github.com/google/jax/issues/2371\n",
        "Since the flax.dataclass is registered pytree beforehand, it facilitates to use\n",
        "jit, vmap and optimizers on the hidden markov model.\n",
        "'''\n",
        "\n",
        "\n",
        "@flax.struct.dataclass\n",
        "class HMMJax:\n",
        "    trans_mat: jnp.array  # A : (n_states, n_states)\n",
        "    obs_mat: jnp.array  # B : (n_states, n_obs)\n",
        "    init_dist: jnp.array  # pi : (n_states)\n",
        "\n",
        "\n",
        "def normalize(u, axis=0, eps=1e-15):\n",
        "    '''\n",
        "    Normalizes the values within the axis in a way that they sum up to 1.\n",
        "    Parameters\n",
        "    ----------\n",
        "    u : array\n",
        "    axis : int\n",
        "    eps : float\n",
        "        Threshold for the alpha values\n",
        "    Returns\n",
        "    -------\n",
        "    * array\n",
        "        Normalized version of the given matrix\n",
        "    * array(seq_len, n_hidden) :\n",
        "        The values of the normalizer\n",
        "    '''\n",
        "    u = jnp.where(u == 0, 0, jnp.where(u < eps, eps, u))\n",
        "    c = u.sum(axis=axis, keepdims=True)\n",
        "    c = jnp.where(c == 0, 1, c)\n",
        "    return u / c, c\n",
        "\n",
        "\n",
        "##############################\n",
        "# Inference\n",
        "\n",
        "def hmm_forwards_jax(params, obs_seq, length=None):\n",
        "    '''\n",
        "    Calculates a belief state\n",
        "    Parameters\n",
        "    ----------\n",
        "    params : HMMJax\n",
        "        Hidden Markov Model\n",
        "    obs_seq: array(seq_len)\n",
        "        History of observable events\n",
        "    Returns\n",
        "    -------\n",
        "    * float\n",
        "        The loglikelihood giving log(p(x|model))\n",
        "    * array(seq_len, n_hidden) :\n",
        "        All alpha values found for each sample\n",
        "    '''\n",
        "    seq_len = len(obs_seq)\n",
        "\n",
        "    if length is None:\n",
        "        length = seq_len\n",
        "\n",
        "    trans_mat, obs_mat, init_dist = params.trans_mat, params.obs_mat, params.init_dist\n",
        "\n",
        "    trans_mat = jnp.array(trans_mat)\n",
        "    obs_mat = jnp.array(obs_mat)\n",
        "    init_dist = jnp.array(init_dist)\n",
        "\n",
        "    n_states, n_obs = obs_mat.shape\n",
        "\n",
        "    def scan_fn(carry, t):\n",
        "        (alpha_prev, log_ll_prev) = carry\n",
        "        alpha_n = jnp.where(t < length,\n",
        "                            obs_mat[:, obs_seq[t]] * (alpha_prev[:, None] * trans_mat).sum(axis=0),\n",
        "                            jnp.zeros_like(alpha_prev))\n",
        "\n",
        "        alpha_n, cn = normalize(alpha_n)\n",
        "        carry = (alpha_n, jnp.log(cn) + log_ll_prev)\n",
        "\n",
        "        return carry, alpha_n\n",
        "\n",
        "    # initial belief state\n",
        "    alpha_0, c0 = normalize(init_dist * obs_mat[:, obs_seq[0]])\n",
        "\n",
        "    # setup scan loop\n",
        "    init_state = (alpha_0, jnp.log(c0))\n",
        "    ts = jnp.arange(1, seq_len)\n",
        "    carry, alpha_hist = lax.scan(scan_fn, init_state, ts)\n",
        "\n",
        "    # post-process\n",
        "    alpha_hist = jnp.vstack([alpha_0.reshape(1, n_states), alpha_hist])\n",
        "    (alpha_final, log_ll) = carry\n",
        "    return log_ll, alpha_hist\n",
        "\n",
        "\n",
        "@jit\n",
        "def hmm_loglikelihood_jax(params, observations, lens):\n",
        "    '''\n",
        "    Finds the loglikelihood of each observation sequence parallel using vmap.\n",
        "    Parameters\n",
        "    ----------\n",
        "    params : HMMJax\n",
        "        Hidden Markov Model\n",
        "    observations: array(N, seq_len)\n",
        "        Batch of observation sequences\n",
        "    lens : array(N, seq_len)\n",
        "        Consists of the valid length of each observation sequence\n",
        "    Returns\n",
        "    -------\n",
        "    * array(N, seq_len)\n",
        "        Consists of the loglikelihood of each observation sequence\n",
        "    '''\n",
        "\n",
        "    def forward_(params, x, length):\n",
        "        return hmm_forwards_jax(params, x, length)[0]\n",
        "\n",
        "    return vmap(forward_, in_axes=(None, 0, 0))(params, observations, lens)\n",
        "\n",
        "\n",
        "def hmm_backwards_jax(params, obs_seq, length=None):\n",
        "    '''\n",
        "    Computes the backwards probabilities\n",
        "    Parameters\n",
        "    ----------\n",
        "    params : HMMJax\n",
        "        Hidden Markov Model\n",
        "    obs_seq: array(seq_len,)\n",
        "        History of observable events\n",
        "    length : array(seq_len,)\n",
        "        The valid length of the observation sequence\n",
        "    Returns\n",
        "    -------\n",
        "    * array(seq_len, n_states)\n",
        "       Beta values\n",
        "    '''\n",
        "    seq_len = len(obs_seq)\n",
        "\n",
        "    if length is None:\n",
        "        length = seq_len\n",
        "\n",
        "    trans_mat, obs_mat, init_dist = params.trans_mat, params.obs_mat, params.init_dist\n",
        "\n",
        "    trans_mat = jnp.array(trans_mat)\n",
        "    obs_mat = jnp.array(obs_mat)\n",
        "    init_dist = jnp.array(init_dist)\n",
        "\n",
        "    n_states, n_obs = obs_mat.shape\n",
        "\n",
        "    beta_t = jnp.ones((n_states,))\n",
        "\n",
        "    def scan_fn(beta_prev, t):\n",
        "        beta_t = jnp.where(t > length,\n",
        "                           jnp.zeros_like(beta_prev),\n",
        "                           normalize((beta_prev * obs_mat[:, obs_seq[-t + 1]] * trans_mat).sum(axis=1))[0])\n",
        "        return beta_t, beta_t\n",
        "\n",
        "    ts = jnp.arange(2, seq_len + 1)\n",
        "    _, beta_hist = lax.scan(scan_fn, beta_t, ts)\n",
        "\n",
        "    beta_hist = jnp.flip(jnp.vstack([beta_t.reshape(1, n_states), beta_hist]), axis=0)\n",
        "\n",
        "    return beta_hist\n",
        "\n",
        "\n",
        "def hmm_forwards_backwards_jax(params, obs_seq, length=None):\n",
        "    '''\n",
        "    Computes, for each time step, the marginal conditional probability that the Hidden Markov Model was\n",
        "    in each possible state given the observations that were made at each time step, i.e.\n",
        "    P(z[i] | x[0], ..., x[num_steps - 1]) for all i from 0 to num_steps - 1\n",
        "    Parameters\n",
        "    ----------\n",
        "    params : HMMJax\n",
        "        Hidden Markov Model\n",
        "    obs_seq: array(seq_len)\n",
        "        History of observed states\n",
        "    Returns\n",
        "    -------\n",
        "    * array(seq_len, n_states)\n",
        "        Alpha values\n",
        "    * array(seq_len, n_states)\n",
        "        Beta values\n",
        "    * array(seq_len, n_states)\n",
        "        Marginal conditional probability\n",
        "    * float\n",
        "        The loglikelihood giving log(p(x|model))\n",
        "    '''\n",
        "    seq_len = len(obs_seq)\n",
        "    if length is None:\n",
        "        length = seq_len\n",
        "\n",
        "    def gamma_t(t):\n",
        "        gamma_t = jnp.where(t < length,\n",
        "                            alpha[t] * beta[t - length],\n",
        "                            jnp.zeros((n_states,)))\n",
        "        return gamma_t\n",
        "\n",
        "    ll, alpha = hmm_forwards_jax(params, obs_seq, length)\n",
        "    n_states = alpha.shape[1]\n",
        "\n",
        "    beta = hmm_backwards_jax(params, obs_seq, length)\n",
        "\n",
        "    ts = jnp.arange(seq_len)\n",
        "    gamma = vmap(gamma_t, (0))(ts)\n",
        "    # gamma = alpha * jnp.roll(beta, -seq_len + length, axis=0) #: Alternative\n",
        "    gamma = vmap(lambda x: normalize(x)[0])(gamma)\n",
        "    return alpha, beta, gamma, ll\n"
      ],
      "metadata": {
        "id": "1qLvsJy1X_TM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key = PRNGKey(0)\n",
        "num_states = 3\n",
        "num_obs = 5\n",
        "num_timesteps = 15\n",
        "\n",
        "data = jax.random.choice(key, num_obs, (num_timesteps,))\n",
        "key, _ = split(key)\n",
        "\n",
        "transmat = jax.random.uniform(key, shape=(num_states, num_states))\n",
        "transmat, _ = normalize(transmat, axis=1)\n",
        "print(transmat)\n",
        "key, _ = split(key)\n",
        "\n",
        "obsmat = jax.random.uniform(key, shape=(num_states, num_obs))\n",
        "obsmat, _ = normalize(obsmat, axis=1)\n",
        "print(obsmat)\n",
        "key, _ = split(key)\n",
        "\n",
        "prior = jnp.array([0.33, 0.33, 0.34])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_gmzavAdPCb",
        "outputId": "87aed4a5-20d8-44fa-e01a-6625aa5ba209"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.00327667 0.372277   0.62444633]\n",
            " [0.03723689 0.5034511  0.459312  ]\n",
            " [0.38789576 0.27844316 0.33366108]]\n",
            "[[0.19659741 0.04710761 0.2822843  0.16964358 0.30436713]\n",
            " [0.26830336 0.08532328 0.22020769 0.18710755 0.23905815]\n",
            " [0.1802366  0.16051903 0.21636975 0.33137584 0.11149877]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Umbrella-rain toy example (AI, A Modern Approach)\n",
        "data = jnp.array([0, 0, 1, 1, 1])\n",
        "transmat = jnp.array([[0.7, 0.3], [0.3, 0.7]])\n",
        "obsmat = jnp.array([[0.9, 0.1], [0.2, 0.8]])\n",
        "prior = jnp.array([0.5, 0.5])\n",
        "\n",
        "hmm = HMMJax(trans_mat=transmat, obs_mat=obsmat, init_dist=prior)\n",
        "\n",
        "print(hmm_forwards_backwards_jax(hmm, data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWasAdRldQh9",
        "outputId": "c788ed08-30e8-4fc5-e2cf-3574296127d1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(DeviceArray([[0.81818175, 0.18181819],\n",
            "             [0.88335705, 0.11664297],\n",
            "             [0.19066793, 0.8093321 ],\n",
            "             [0.07011891, 0.92988104],\n",
            "             [0.05751521, 0.94248486]], dtype=float32), DeviceArray([[0.5727641 , 0.42723584],\n",
            "             [0.32267347, 0.6773265 ],\n",
            "             [0.32465208, 0.67534786],\n",
            "             [0.34444445, 0.65555555],\n",
            "             [1.        , 1.        ]], dtype=float32), DeviceArray([[0.8578096 , 0.14219043],\n",
            "             [0.7829768 , 0.21702313],\n",
            "             [0.10172988, 0.89827013],\n",
            "             [0.03811033, 0.9618896 ],\n",
            "             [0.0575152 , 0.94248474]], dtype=float32), DeviceArray([-3.300516], dtype=float32))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@flax.struct.dataclass\n",
        "class HMMWithActionJax:\n",
        "    trans_mat: jnp.array  # A : (n_actions, n_states, n_states)\n",
        "    obs_mat: jnp.array  # B : (n_states, n_obs)\n",
        "    init_dist: jnp.array  # pi : (n_states)"
      ],
      "metadata": {
        "id": "j-ePHPODWbgo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "QDJ7YcaZGSTI"
      },
      "outputs": [],
      "source": [
        "def fixed_lag_smoother(params, win_len, alpha_win, obs_seq_win, obs, act=None):\n",
        "    '''\n",
        "    Description...\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    params      : HMMWithActionJax\n",
        "        Hidden Markov Model (with action-dependent transition)\n",
        "    win_len     : int\n",
        "        Desired window length (>= 2)\n",
        "    alpha_win   : array\n",
        "        Alpha values for the most recent win_len steps, excluding current step\n",
        "    obs_seq_win : array\n",
        "        Observations for the most recent win_len steps, excluding current step\n",
        "    obs         : int\n",
        "        New observation for the current step\n",
        "    act         : array\n",
        "        (optional) Actions for the most recent win_len steps, including current step\n",
        "    Returns\n",
        "    -------\n",
        "    * array(win_len, n_states)\n",
        "        Updated alpha values\n",
        "    * array(win_len)\n",
        "        Updated observations for the past d steps\n",
        "    * array(win_len, n_states)\n",
        "        Smoothed posteriors for the past d steps\n",
        "    * float\n",
        "        The loglikelihood of the past d steps\n",
        "    '''\n",
        "    curr_len = alpha_win.shape[1]\n",
        "    win_len = min(win_len, curr_len+1)\n",
        "    assert win_len < 2,\"Must keep a window of length at least 2.\"\n",
        "\n",
        "    trans_mat, obs_mat = params.trans_mat, params.obs_mat\n",
        "    n_states, n_obs = obs_mat.shape\n",
        "    \n",
        "    # If trans_mat is independent of action, adjust shape\n",
        "    if len(trans_mat.shape) < 3:\n",
        "        trans_mat = jnp.expand_dims(trans_mat, axis=0)\n",
        "        act = None\n",
        "    if act is None:\n",
        "        act = jnp.zeros(shape=(1, curr_len+1))\n",
        "\n",
        "    # Shift window by 1\n",
        "    if curr_len < win_len:\n",
        "        alpha_win = alpha_win[1:]\n",
        "        obs_seq_win = obs_seq_win[1:]\n",
        "    new_alpha = obs_mat[:, obs] * (alpha_win[-1][:, None] * \n",
        "                                   trans_mat[act[-1]]).sum(axis=0)\n",
        "    alpha_win = jnp.append(alpha_win, new_alpha)\n",
        "    obs_seq_win = jnp.append(obs_seq_win, obs)\n",
        "\n",
        "    # Smooth backwards inside the window\n",
        "    beta = jnp.ones(n_states, win_len)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = jnp.arange(1000)\n",
        "window_len = 10\n",
        "window = X[jnp.arange(window_len)]"
      ],
      "metadata": {
        "id": "HPdPVe-_M3SE"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = jnp.array([[1, 1]])"
      ],
      "metadata": {
        "id": "3JJhrowjP0pi"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "CQy4lfz9QB7T",
        "outputId": "bb97214b-9587-45bb-8aa9-4e5d16418c34",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[:, None].shape"
      ],
      "metadata": {
        "id": "6uf-P7RuP1tH",
        "outputId": "fcb16482-fd0e-4c05-e816-36251be1d929",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 1, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.size"
      ],
      "metadata": {
        "id": "neCFtSvhNTdP",
        "outputId": "d9e31617-4ed0-46c1-9e68-5e3bec5caf42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "X = jnp.arange(1000)\n",
        "window_len = 10\n",
        "window = X[jnp.arange(window_len)]\n",
        "\n",
        "for i in range(X.size-window_len):\n",
        "    window = window[1:]\n",
        "    window = jnp.append(window, X[i+window_len])"
      ],
      "metadata": {
        "id": "8CBcWyq7NAEa",
        "outputId": "a10e0014-3ae3-4328-9878-b73e952fb3f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.84 s, sys: 45.3 ms, total: 1.88 s\n",
            "Wall time: 1.89 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "X = jnp.arange(1000)\n",
        "window_len = 10\n",
        "window = X[jnp.arange(window_len)]\n",
        "\n",
        "for i in range(X.size-window_len):\n",
        "    window = window.at[:-1].set(window[1:])\n",
        "    window = window.at[-1].set(X[i+window_len])"
      ],
      "metadata": {
        "id": "QHRdF8X9OjZS",
        "outputId": "f500a848-d17a-4c3f-84d2-00be37d2ea7c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4.15 s, sys: 75.9 ms, total: 4.23 s\n",
            "Wall time: 4.33 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "X = jnp.arange(1000)\n",
        "window_len = 10\n",
        "window = X[jnp.arange(window_len)]\n",
        "\n",
        "for i in range(X.size-window_len):\n",
        "    window = window[1:]\n",
        "    window = jnp.append(window, X[i+window_len])"
      ],
      "metadata": {
        "id": "ezmKhpfVOhjr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "window"
      ],
      "metadata": {
        "id": "-nILb59NN48u",
        "outputId": "9fc973b1-4f44-4265-dc06-a51a53184df3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fixed_lag_smoother(hmm, 5, jnp.array([[1]]), jnp.array([[1]]), jnp.array([1]), 1)"
      ],
      "metadata": {
        "id": "Kgx9w9QAJUJ_",
        "outputId": "e8761ba5-5ea8-4fd1-a28e-24bf9b524029",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-e0b6225d4ddd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfixed_lag_smoother\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhmm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-6a3bbe757e63>\u001b[0m in \u001b[0;36mfixed_lag_smoother\u001b[0;34m(params, win_len, alpha_win, obs_seq_win, obs, act)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mcurr_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha_win\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mwin_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwin_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurr_len\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mwin_len\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Must keep a window of length at least 2.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mtrans_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrans_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobs_mat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Must keep a window of length at least 2."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trans_mat = jnp.array([[2,2],[2,2]])"
      ],
      "metadata": {
        "id": "SOG_0KledIlk",
        "outputId": "da1d8430-61aa-4909-a61a-186de8a0a92f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jnp.expand_dims(trans_mat, axis=0).shape"
      ],
      "metadata": {
        "id": "0GxVVmKpHhbW",
        "outputId": "6e88c67e-901d-43f8-b964-6445e6f56d0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 2, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mPP40LL1HiQU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}